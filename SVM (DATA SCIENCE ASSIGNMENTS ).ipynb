{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a007d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de248d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mushroom_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de11ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "mushroom_df = pd.read_csv(r\"C:\\Users\\Acer\\Desktop\\Data Sci Assignments\\SVM\\mushroom.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf0d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "mushroom_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac64faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(mushroom_df.head())\n",
    "\n",
    "# Get basic information about the dataset\n",
    "print(\"\\nDataset Information:\")\n",
    "print(mushroom_df.info())\n",
    "\n",
    "# Summarize the dataset's statistical properties\n",
    "print(\"\\nDataset Summary Statistics:\")\n",
    "print(mushroom_df.describe(include='all'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f547116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot histograms for each feature\n",
    "mushroom_df.hist(bins=30, figsize=(20, 15))\n",
    "plt.suptitle('Histograms of Mushroom Dataset Features')\n",
    "plt.show()\n",
    "\n",
    "# Plot density plots for each feature\n",
    "mushroom_df.plot(kind='density', subplots=True, layout=(8, 3), sharex=False, figsize=(20, 30))\n",
    "plt.suptitle('Density Plots of Mushroom Dataset Features')\n",
    "plt.show()\n",
    "\n",
    "# Investigate feature correlations (only if numeric features are present)\n",
    "# Since the dataset may be entirely categorical, we need to convert it to numerical format first\n",
    "mushroom_encoded = pd.get_dummies(mushroom_df)\n",
    "correlation_matrix = mushroom_encoded.corr()\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Mushroom Dataset')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24189d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot histograms for each categorical feature\n",
    "categorical_columns = mushroom_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(categorical_columns)//3+1, ncols=3, figsize=(15, 20))\n",
    "fig.suptitle('Histograms of Mushroom Dataset Categorical Features')\n",
    "\n",
    "for i, col in enumerate(categorical_columns):\n",
    "    ax = axes[i//3, i%3]\n",
    "    mushroom_df[col].value_counts().plot(kind='bar', ax=ax, title=col)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Plot density plots for numeric features\n",
    "numeric_columns = mushroom_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(numeric_columns), ncols=1, figsize=(10, 15))\n",
    "fig.suptitle('Density Plots of Mushroom Dataset Numeric Features')\n",
    "\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    ax = axes[i]\n",
    "    sns.kdeplot(mushroom_df[col], ax=ax)\n",
    "    ax.set_title(col)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Investigate feature correlations (only if numeric features are present)\n",
    "# Since the dataset may be entirely categorical, we need to convert it to numerical format first\n",
    "mushroom_encoded = pd.get_dummies(mushroom_df)\n",
    "correlation_matrix = mushroom_encoded.corr()\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Mushroom Dataset')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9234335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    mushroom_df[column] = le.fit_transform(mushroom_df[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Define features and target variable\n",
    "X = mushroom_df.drop(['class'], axis=1)\n",
    "y = mushroom_df['class']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b65e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=mushroom_df, x='class')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Pair plot to visualize relationships (sampled for performance)\n",
    "sampled_df = mushroom_df.sample(500, random_state=42)\n",
    "sns.pairplot(sampled_df, hue='class', markers=[\"o\", \"s\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eada63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(data=mushroom_df, x='class')\n",
    "plt.title('Class Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Pair plot to visualize relationships (sampled for performance)\n",
    "sampled_df = mushroom_df.sample(500, random_state=42)\n",
    "sns.pairplot(sampled_df, hue='class', markers=[\"o\", \"s\"])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a031c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Implement a basic SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Train the SVM model on the training data\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "accuracy, precision, recall, f1, conf_matrix, class_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_confusion_matrix(svm_classifier, X_test, y_test, cmap='Blues', values_format='d')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot decision boundary for the two numeric features (stalk_height and cap_diameter)\n",
    "def plot_decision_boundary(X, y, model, title):\n",
    "    x_min, x_max = X.iloc[:, 0].min() - 1, X.iloc[:, 0].max() + 1\n",
    "    y_min, y_max = X.iloc[:, 1].min() - 1, X.iloc[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))\n",
    "    \n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3)\n",
    "    plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, edgecolors='k', marker='o')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(X.columns[0])\n",
    "    plt.ylabel(X.columns[1])\n",
    "    plt.show()\n",
    "\n",
    "# Extract only the two numeric features for plotting\n",
    "numeric_features = X_train[['stalk_height', 'cap_diameter']]\n",
    "svm_numeric = SVC().fit(numeric_features, y_train)\n",
    "\n",
    "# Plot decision boundary\n",
    "plot_decision_boundary(numeric_features, y_train, svm_numeric, 'SVM Decision Boundary for Numeric Features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example Data Preparation\n",
    "# X and y should be defined as your feature matrix and target vector\n",
    "# X_train, X_test, y_train, y_test should be created using train_test_split\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Create and fit the GridSearchCV object\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=2, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and predictions\n",
    "best_svm = grid.best_estimator_\n",
    "y_pred_best = best_svm.predict(X_test)\n",
    "\n",
    "# Calculate and print metrics\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "precision_best = precision_score(y_test, y_pred_best, average='weighted')\n",
    "recall_best = recall_score(y_test, y_pred_best, average='weighted')\n",
    "f1_best = f1_score(y_test, y_pred_best, average='weighted')\n",
    "conf_matrix_best = confusion_matrix(y_test, y_pred_best)\n",
    "class_report_best = classification_report(y_test, y_pred_best)\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Accuracy:\", accuracy_best)\n",
    "print(\"Precision:\", precision_best)\n",
    "print(\"Recall:\", recall_best)\n",
    "print(\"F1 Score:\", f1_best)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
    "print(\"Classification Report:\\n\", class_report_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abde62c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for displaying the results\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Accuracy:\", accuracy_best)\n",
    "print(\"Precision:\", precision_best)\n",
    "print(\"Recall:\", recall_best)\n",
    "print(\"F1 Score:\", f1_best)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix_best)\n",
    "print(\"Classification Report:\\n\", class_report_best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ec191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_decision_boundaries(X, y, model):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', marker='o')\n",
    "    plt.title(\"SVM Decision Boundaries\")\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "    plt.show()\n",
    "\n",
    "# Assuming X_train_reduced and y_train are your 2D feature and target arrays\n",
    "plot_decision_boundaries(X_train_reduced, y_train, best_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbc43ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If predictions need to be visualized\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(np.arange(len(y_test)), y_test, color='blue', label='True labels')\n",
    "plt.scatter(np.arange(len(y_test)), y_pred_best, color='red', label='Predicted labels')\n",
    "plt.title('True vs Predicted Labels')\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Label')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5dbdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results for different kernels (assuming you stored results)\n",
    "print(\"Kernel Comparison Results:\")\n",
    "for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    print(f\"Kernel: {kernel}\")\n",
    "    # Retrieve metrics for each kernel if saved\n",
    "    # Example: accuracy_kernel = results_dict[kernel]['accuracy']\n",
    "    print(f\"Accuracy: {accuracy_kernel}\")\n",
    "    print(f\"Precision: {precision_kernel}\")\n",
    "    print(f\"Recall: {recall_kernel}\")\n",
    "    print(f\"F1 Score: {f1_kernel}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f8abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM Strengths: Effective in high-dimensional spaces, robust to overfitting, flexible with kernels, and clear margin separation.\n",
    "#SVM Weaknesses: Computationally expensive, sensitive to feature scaling, challenging hyperparameter tuning, and less interpretable.\n",
    "\n",
    "#Practical Implications: Suitable for high-dimensional, complex classification tasks but may struggle with large datasets and require careful tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5817b08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ab0da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
