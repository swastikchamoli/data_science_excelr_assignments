{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171bcf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'C:\\\\Users\\\\Acer\\\\Desktop\\\\Data Sci Assignments\\\\Clustering\\\\EastWestAirlines.xlsx'\n",
    "df = pd.read_excel(file_path, sheet_name='data')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(df.info())\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d503f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to remove outliers using IQR\n",
    "def remove_outliers(df):\n",
    "    Q1 = df.quantile(0.25)\n",
    "    Q3 = df.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return df[~((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "# Remove outliers\n",
    "df_clean = remove_outliers(df)\n",
    "print(df_clean.info())\n",
    "print(df_clean.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f942f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any None or NaN values in the cleaned dataset\n",
    "print(\"Missing values after outlier removal:\\n\", df_clean.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577039db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df_clean.iloc[:, 1:]), columns=df_clean.columns[1:])\n",
    "\n",
    "# Check for any None or NaN values in the scaled dataset\n",
    "print(\"Missing values after scaling:\\n\", df_scaled.isnull().sum())\n",
    "print(df_scaled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde754f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df_clean.iloc[:, 1:]), columns=df_clean.columns[1:])\n",
    "\n",
    "# Check for any None or NaN values in the scaled dataset\n",
    "print(\"Missing values after scaling:\\n\", df_scaled.isnull().sum())\n",
    "print(df_scaled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8372df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize the distribution of each feature\n",
    "df_scaled.hist(bins=30, figsize=(15, 10))\n",
    "plt.show()\n",
    "\n",
    "# Use pair plots to understand relationships between features\n",
    "sns.pairplot(df_scaled)\n",
    "plt.show()\n",
    "\n",
    "# Check for correlations between features\n",
    "corr_matrix = df_scaled.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc7bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Create a linkage matrix\n",
    "Z = linkage(df_scaled, method='ward')\n",
    "\n",
    "# Plot the dendrogram\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(Z)\n",
    "plt.title('Dendrogram for Hierarchical Clustering')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()\n",
    "\n",
    "# Apply Hierarchical clustering with the optimal number of clusters (e.g., k=3)\n",
    "hierarchical = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
    "clusters_hierarchical = hierarchical.fit_predict(df_scaled)\n",
    "\n",
    "# Add the cluster labels to the dataset\n",
    "df_scaled['Cluster_Hierarchical'] = clusters_hierarchical\n",
    "\n",
    "# Evaluate the clustering quality using the silhouette score\n",
    "silhouette_avg_hierarchical = silhouette_score(df_scaled.iloc[:, :-2], clusters_hierarchical)\n",
    "print(f'Silhouette Score for Hierarchical Clustering: {silhouette_avg_hierarchical}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb90660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Apply DBSCAN clustering\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "clusters_dbscan = dbscan.fit_predict(df_scaled)\n",
    "\n",
    "# Add the cluster labels to the dataset\n",
    "df_scaled['Cluster_DBSCAN'] = clusters_dbscan\n",
    "\n",
    "# Evaluate the clustering quality using the silhouette score\n",
    "# Note: For DBSCAN, clusters with label -1 are noise and should be excluded from silhouette score calculation\n",
    "silhouette_avg_dbscan = silhouette_score(df_scaled.iloc[:, :-3][clusters_dbscan != -1], clusters_dbscan[clusters_dbscan != -1])\n",
    "print(f'Silhouette Score for DBSCAN: {silhouette_avg_dbscan}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23858d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical Clustering\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=df_scaled, x='Balance', y='Bonus_miles', hue='Cluster_Hierarchical', palette='viridis')\n",
    "plt.title('Hierarchical Clustering')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd9260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=df_scaled, x='Balance', y='Bonus_miles', hue='Cluster_DBSCAN', palette='viridis')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073e0720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
